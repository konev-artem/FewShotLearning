{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fewshot.data_provider.dataset import Dataset\n",
    "from fewshot.backbones import ConvNet\n",
    "\n",
    "from fewshot.algorithms.fewshot_models import BaselineFewShotModel\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import scipy.stats as st\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from fewshot.tester import Tester\n",
    "\n",
    "from fewshot.algorithms.backbone_train import (\n",
    "    simple_one_layer_cross_entropy_train,\n",
    "    simple_cosine_layer_cross_entropy_train\n",
    ")\n",
    "\n",
    "from fewshot.algorithms.fewshot_test import baseline_fewshot_test, bootstrap\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init\n",
    "\n",
    "Set up all input data and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 prepare_dataset.py omniglot --dataset_root '../fewshot/datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing omniglot as in the $\\href{https://openreview.net/pdf?id=HkxLXnAcFQ}{article}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_omniglot(omniglot_dir):\n",
    "    file = open(os.path.join(omniglot_dir, 'data.csv'))\n",
    "    smth = pd.read_csv(file)\n",
    "    file.close()\n",
    "    appendix = []\n",
    "    for i in tqdm_notebook(range(smth.shape[0])):\n",
    "        string = smth.loc[i]\n",
    "        filepath = string['filepath']\n",
    "        class_ = string['class']\n",
    "        super_class = string['super_class']\n",
    "        subset = string['subset']\n",
    "        filepath = os.path.join(omniglot_dir, filepath)\n",
    "        img = cv2.imread(filepath)\n",
    "        img90 = cv2.rotate(img, rotateCode=0)\n",
    "        img180 = cv2.rotate(img, rotateCode=1)\n",
    "        img270 = cv2.rotate(img, rotateCode=2)\n",
    "        fp = filepath.split('/')\n",
    "        name_90 = fp[-1].split('.')[0] + '_flip_90.png'\n",
    "        path_90 = os.path.join('/'.join(fp[:-1]), name_90)\n",
    "        name_180 = fp[-1].split('.')[0] + '_flip_180.png'\n",
    "        path_180 = os.path.join('/'.join(fp[:-1]), name_180)\n",
    "        name_270 = fp[-1].split('.')[0] + '_flip_270.png'\n",
    "        path_270 = os.path.join('/'.join(fp[:-1]), name_270)\n",
    "        cv2.imwrite(path_90, img90)\n",
    "        cv2.imwrite(path_180, img180)\n",
    "        cv2.imwrite(path_270, img270)\n",
    "        appendix.append({\n",
    "            'filepath': path_90.split(omniglot_dir)[1],\n",
    "            'class': class_ + '_flip_90',\n",
    "            'super_class': super_class,\n",
    "            'subset': subset\n",
    "        })\n",
    "        appendix.append({\n",
    "            'filepath': path_180.split(omniglot_dir)[1],\n",
    "            'class': class_ + '_flip_180',\n",
    "            'super_class': super_class,\n",
    "            'subset': subset\n",
    "        })\n",
    "        appendix.append({\n",
    "            'filepath': path_270.split(omniglot_dir)[1],\n",
    "            'class': class_ + '_flip_270',\n",
    "            'super_class': super_class,\n",
    "            'subset': subset\n",
    "        })\n",
    "    appendix = pd.DataFrame(appendix, columns=['filepath', 'class', 'super_class', 'subset'])\n",
    "    app = pd.merge(smth, appendix, 'outer')\n",
    "    app.to_csv(os.path.join(omniglot_dir, 'data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augment_omniglot('../fewshot/datasets/omniglot/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 resize_images.py \"omniglot\" \"28, 28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common\n",
    "seed = 42\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_depth = 3\n",
    "\n",
    "# classes\n",
    "base_num_classes = 4112\n",
    "novel_num_classes = 1692\n",
    "val_num_classes = 688  # not used in baseline algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fewshot training and testing\n",
    "n_way = 5\n",
    "k_shot = 5\n",
    "fewshot_batch_size = 4\n",
    "support_epochs = 100\n",
    "query_size = 16\n",
    "\n",
    "support_generator_args={\n",
    "    \"size\": (int(img_width * 1.15), int(img_height * 1.15)),\n",
    "    \"center\": True,  # for center cropping,\n",
    "    \"crop_size\": (img_width, img_height),\n",
    "}\n",
    "\n",
    "query_generator_args={\n",
    "    \"size\": (int(img_width * 1.15), int(img_height * 1.15)),\n",
    "    \"center\": True,  # for center cropping,\n",
    "    \"crop_size\": (img_width, img_height),\n",
    "}\n",
    "\n",
    "n_episodes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone training\n",
    "backbone_training_batch_size = 16\n",
    "backbone_training_epochs = 5\n",
    "\n",
    "backbone_generator_args={\n",
    "    \"size\": (int(img_width * 1.15), int(img_height * 1.15)),\n",
    "    \"center\": True,  # for center cropping,\n",
    "    \"crop_size\": (img_width, img_height),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../fewshot/datasets/omniglot/\"\n",
    "dataset = Dataset(dataset_dir=dataset_dir, csv_name=\"data_28x28.csv\", image_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone\n",
    "Create backbone dataset (80 classes), split to train and validattion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split by classes with train size = 4112 (seed = 42)\n",
      "Train classes: 4112\n",
      "Test classes: 2380\n",
      "Train data: 82240 samples\n",
      "Test data:  47600 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "backbone_dataset, val_fewshot_dataset = dataset.split_by_classes(train_size=base_num_classes,\n",
    "                                                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split by classes with train size = 688 (seed = 42)\n",
      "Train classes: 688\n",
      "Test classes: 1692\n",
      "Train data: 13760 samples\n",
      "Test data:  33840 samples\n"
     ]
    }
   ],
   "source": [
    "val_dataset, fewshot_dataset = val_fewshot_dataset.split_by_classes(train_size=val_num_classes,\n",
    "                                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "backbone = ConvNet(input_size=(img_width, img_height, img_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../fewshot/checkpoints'\n",
    "log_dir = '../fewshot/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_optimizer = tf.keras.optimizers.Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: incapsulate inside fewshot library\n",
    "backbone_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"../fewshot/checkpoints/weights.{epoch:02d}-{loss:.2f}.hdf5\",\n",
    "                                           monitor=\"loss\",\n",
    "                                       save_best_only=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simple_one_layer_cross_entropy_train(\n",
    "    backbone,\n",
    "    backbone_dataset.get_batch_generator(batch_size=backbone_training_batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         generator_args=backbone_generator_args),\n",
    "    epochs=backbone_training_epochs,\n",
    "    optimizer=backbone_optimizer,\n",
    "    model_name=model_name,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    period=5,\n",
    "    tensorboard=True,\n",
    "    log_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot\n",
    "Train fewshot model, 5-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=5, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_optimizer = tf.keras.optimizers.Adam(lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=True)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=False)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot\n",
    "Train fewshot model, 1-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=1, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=True)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "#                                    log_dir=log_dir,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=False)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "#                                    log_dir=log_dir,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ConvNet(input_size=(img_width, img_height, img_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../fewshot/checkpoints'\n",
    "log_dir = '../fewshot/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_optimizer = tf.keras.optimizers.Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"../fewshot/checkpoints/cos_weights.{epoch:02d}-{loss:.2f}.hdf5\",\n",
    "                                           monitor=\"loss\",\n",
    "                                       save_best_only=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "5140/5140 [==============================] - 508s 99ms/step - loss: 6.6147 - acc: 0.0542\n",
      "Epoch 2/5\n",
      "5140/5140 [==============================] - 520s 101ms/step - loss: 3.7599 - acc: 0.2838\n",
      "Epoch 3/5\n",
      "5140/5140 [==============================] - 557s 108ms/step - loss: 2.4400 - acc: 0.4926\n",
      "Epoch 4/5\n",
      "5140/5140 [==============================] - 546s 106ms/step - loss: 1.8304 - acc: 0.6045\n",
      "Epoch 5/5\n",
      "5140/5140 [==============================] - 538s 105ms/step - loss: 1.4910 - acc: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fewshot.backbones.convnet.ConvNet at 0x13420f5f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cosine_layer_cross_entropy_train(\n",
    "    backbone,\n",
    "    backbone_dataset.get_batch_generator(batch_size=backbone_training_batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         generator_args=backbone_generator_args),\n",
    "    epochs=backbone_training_epochs,\n",
    "    optimizer=backbone_optimizer,\n",
    "    model_name=model_name,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    period=5,\n",
    "    tensorboard=True,\n",
    "    log_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot\n",
    "Train fewshot model, 5-shot, with cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=5, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_optimizer = tf.keras.optimizers.Adam(lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average acc: 97.80%: 100%|██████████| 50/50 [04:28<00:00,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=True)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: accuracy, mean: 0.98, std: 0.03, 95% conf interval: [0.97 ,0.98]\n"
     ]
    }
   ],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.978, std:0.026, conf.invterval:[0.970,0.985]\n"
     ]
    }
   ],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train fewshot model, 5-shot, without cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=5, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average acc: 97.62%: 100%|██████████| 50/50 [06:59<00:00,  9.52s/it]\n"
     ]
    }
   ],
   "source": [
    "fewshot_optimizer = tf.keras.optimizers.Adam(lr=1e-3) \n",
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=False)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: accuracy, mean: 0.98, std: 0.03, 95% conf interval: [0.97 ,0.98]\n"
     ]
    }
   ],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.976, std:0.027, conf.invterval:[0.969,0.983]\n"
     ]
    }
   ],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot\n",
    "Train fewshot model, 1-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=1, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average acc: 93.58%: 100%|██████████| 50/50 [14:46<00:00, 19.69s/it]\n"
     ]
    }
   ],
   "source": [
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=True)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: accuracy, mean: 0.94, std: 0.07, 95% conf interval: [0.92 ,0.95]\n"
     ]
    }
   ],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.936, std:0.071, conf.invterval:[0.915,0.954]\n"
     ]
    }
   ],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train fewshot model, 1-shot, without cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_generator = fewshot_dataset.get_fewshot_generator(n_way=n_way, \n",
    "                                                          k_shot=1, \n",
    "                                                          query_size=query_size,\n",
    "                                                          support_generator_args=support_generator_args,\n",
    "                                                          query_generator_args=query_generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average acc: 93.08%: 100%|██████████| 50/50 [11:24<00:00, 15.40s/it]\n"
     ]
    }
   ],
   "source": [
    "fewshot_optimizer = tf.keras.optimizers.Adam(lr=1e-3) \n",
    "fewshot_model = BaselineFewShotModel(backbone, n_way, with_cosine=False)\n",
    "accuracies = baseline_fewshot_test(model=fewshot_model,\n",
    "                                   generator=episode_generator, \n",
    "                                   optimizer=fewshot_optimizer,\n",
    "                                   batch_size=fewshot_batch_size,\n",
    "                                   support_epochs=support_epochs,\n",
    "                                   n_episodes=n_episodes,\n",
    "                                   model_name='baseline-fewshot',\n",
    "                                   tensorboard=True,\n",
    "                                   period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: accuracy, mean: 0.93, std: 0.07, 95% conf interval: [0.91 ,0.95]\n"
     ]
    }
   ],
   "source": [
    "mean_one_shot, std_one_shot, left_bound_one_shot, right_bound_one_shot = bootstrap(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.931, std:0.072, conf.invterval:[0.911,0.950]\n"
     ]
    }
   ],
   "source": [
    "print('mean:{:0.3f}, std:{:0.3f}, conf.invterval:[{:0.3f},{:0.3f}]'.format(mean_one_shot, std_one_shot, \n",
    "                                                                    left_bound_one_shot, right_bound_one_shot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
